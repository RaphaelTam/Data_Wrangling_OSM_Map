{
 "metadata": {
  "name": "",
  "signature": "sha256:8e9f3a9bc02fa50528815dabae3d5dad76c8b2ada1b815d6f0b8b23c8bb3bfd6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "This project audits OpenStreetMap (http://www.openstreetmap.org) data.  OSM data is open and crowd sourced by map enthusiasts\n",
      "who have exceptional knowledge of the locale.  Very granuldar information down to bike parking area, water fountains, post boxes\n",
      "are avaialble.\n",
      "\n",
      "The area chosen for this project has a boundary of 37.7894 - 37.9236 in latitude and -122.328 - -122.206 in longitude.\n",
      "It covers Albay, Berkeley and part of Oakland in the San Francisco Bay Area.  The objectives:\n",
      "    1. Shape the data into a model more suited for data analysis.\n",
      "    2. Audit the map data for problems in consistency and uniformity.\n",
      "    3. Provide statistics summarizing the data\n",
      "    4. Propose a way to clean the data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load data.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Wed Dec 17 11:45:34 2014\n",
      "\n",
      "@author: raphaeltam\n",
      "\"\"\"\n",
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "import codecs\n",
      "import json\n",
      "\n",
      "\"\"\"\n",
      "The first task is to wrangle the data and transform the shape of the data\n",
      "into a model more suited for data analysis. The output is a list of dictionaries\n",
      "that look like this:\n",
      "\n",
      "{\n",
      "\"id\": \"2406124091\",\n",
      "\"type: \"node\",\n",
      "\"visible\":\"true\",\n",
      "\"created\": {\n",
      "          \"version\":\"2\",\n",
      "          \"changeset\":\"17206049\",\n",
      "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
      "          \"user\":\"linuxUser16\",\n",
      "          \"uid\":\"1219059\"\n",
      "        },\n",
      "\"pos\": [41.9757030, -87.6921867],\n",
      "\"address\": {\n",
      "          \"housenumber\": \"5157\",\n",
      "          \"postcode\": \"60625\",\n",
      "          \"street\": \"North Lincoln Ave\"\n",
      "        },\n",
      "\"amenity\": \"restaurant\",\n",
      "\"cuisine\": \"mexican\",\n",
      "\"name\": \"La Cabana De Don Luis\",\n",
      "\"phone\": \"1 (773)-271-5176\"\n",
      "}\n",
      "\n",
      "The function 'shape_element' processes the element from xml.etree.ElementTree.iterparse\n",
      "and returns a dictionary, containing the shaped data for that element.  Shaped data is \n",
      "stored in a file, so that mongoimport can be used later on to import the shaped data into \n",
      "MongoDB. \n",
      "\n",
      "In particular the following things are done:\n",
      "- I will process only 2 types of top level tags: \"node\" and \"way\"\n",
      "- all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n",
      "    - attributes in the CREATED array should be added under a key \"created\"\n",
      "    - attributes for latitude and longitude should be added to a \"pos\" array,\n",
      "      for use in geospacial indexing.  The values inside \"pos\" array are floats\n",
      "      and not strings. \n",
      "- if second level tag \"k\" value contains problematic characters, it will be ignored\n",
      "- if second level tag \"k\" value starts with \"addr:\", it will be added to a dictionary \"address\"\n",
      "- if second level tag \"k\" value does not start with \"addr:\", but contains \":\", it is processed\n",
      "  same as any other tag.\n",
      "- if there is a second \":\" that separates the type/direction of a street,\n",
      "  the tag will be ignored, for example:\n",
      "\n",
      "<tag k=\"addr:housenumber\" v=\"5158\"/>\n",
      "<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
      "<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
      "<tag k=\"addr:street:prefix\" v=\"North\"/>\n",
      "<tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
      "<tag k=\"amenity\" v=\"pharmacy\"/>\n",
      "\n",
      "  will be turned into:\n",
      "\n",
      "{...\n",
      "\"address\": {\n",
      "    \"housenumber\": 5158,\n",
      "    \"street\": \"North Lincoln Avenue\"\n",
      "}\n",
      "\"amenity\": \"pharmacy\",\n",
      "...\n",
      "}\n",
      "\n",
      "- for \"way\" specifically:\n",
      "\n",
      "  <nd ref=\"305896090\"/>\n",
      "  <nd ref=\"1719825889\"/>\n",
      "\n",
      "will be turned into\n",
      "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
      "\"\"\"\n",
      "lower = re.compile(r'^([a-z]|_)*$')\n",
      "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
      "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
      "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
      "\n",
      "\"\"\"\n",
      "Process address related information\n",
      "\"\"\"\n",
      "def p_addr(element):\n",
      "    addr_dic = {}\n",
      "    for t in element.iter('tag'):\n",
      "        if t.attrib.has_key('k'):\n",
      "            if t.attrib['k']=='addr:housenumber':\n",
      "                addr_dic['housenumber'] = t.attrib['v']\n",
      "                continue\n",
      "            if t.attrib['k'] == 'addr:street':\n",
      "                addr_dic['street'] = t.attrib['v']\n",
      "                continue\n",
      "            if t.attrib['k'] == 'addr:postcode':\n",
      "                addr_dic['postcode'] = t.attrib['v']\n",
      "                continue\n",
      "    return addr_dic\n",
      "\n",
      "\"\"\"\n",
      "Process amenity related information\"\n",
      "\"\"\"    \n",
      "def p_amenity(element):\n",
      "    a_d = {}\n",
      "    for t in element.iter('tag'):\n",
      "        if t.attrib['k'] == 'amenity':\n",
      "            a_d['amenity'] = t.attrib['v']\n",
      "        if t.attrib['k'] == 'name':\n",
      "            a_d['name'] = t.attrib['v']\n",
      "        if t.attrib['k'] == 'phone':\n",
      "            a_d['phone'] = t.attrib['v']\n",
      "        if t.attrib['k'] == 'cuisine':\n",
      "            a_d['cuisine'] = t.attrib['v']\n",
      "        continue\n",
      "    return a_d     \n",
      "            \n",
      "    \n",
      "#process 'created' information   \n",
      "def p_created(element):\n",
      "    cr_dict = {}\n",
      "    for cr in CREATED:\n",
      "        cr_dict[cr] = element.attrib[cr]\n",
      "    return cr_dict\n",
      "\n",
      "\"\"\"\n",
      "Returns True if the address has a housenumber key\n",
      "\"\"\"\n",
      "def is_structure(element):\n",
      "    for e in element.iter('tag'):\n",
      "        if e.attrib['k'] == 'addr:housenumber':\n",
      "            return True           \n",
      "    return False  \n",
      "    \n",
      "\"\"\"\n",
      "Retruns true if the node has amenity information\n",
      "\"\"\"    \n",
      "def has_amenity(element):\n",
      "    for e in element.iter('tag'):\n",
      "        if e.attrib['k'] == 'amenity':\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "def p_pos(element):\n",
      "    return [float(element.attrib['lat']), float(element.attrib['lon'])]  \n",
      "            \n",
      "\"\"\"\n",
      "process node elements, pack data into data model\n",
      "\"\"\"          \n",
      "def p_node(element):\n",
      "    node = {}\n",
      "    node['id'] = element.attrib['id']\n",
      "    node['type'] = 'node'\n",
      "    if element.attrib.has_key('visible'):\n",
      "        node['visible'] = 'true'\n",
      "    node['created'] = p_created(element)\n",
      "    node['pos'] = p_pos(element)\n",
      "    if is_structure(element):\n",
      "        node['address'] = p_addr(element)\n",
      "    if has_amenity(element):\n",
      "        for k,v in p_amenity(element).iteritems():\n",
      "            node[k] = v\n",
      "    return node\n",
      "\"\"\" \n",
      "process way elements and their associated nd tags\n",
      "\"\"\"\n",
      "def p_nd(element):\n",
      "    nd_list = []\n",
      "    for t in element.iter('nd'):\n",
      "        nd_list.append(t.attrib['ref'])\n",
      "    return nd_list\n",
      "    \n",
      "def p_way(element):\n",
      "    node = {}\n",
      "    node['id'] = element.attrib['id']\n",
      "    node['type'] = 'way'\n",
      "    node['created'] = p_created(element)\n",
      "    node['node_refs'] = p_nd(element)\n",
      "    if is_structure (element):\n",
      "        node['address'] = p_addr(element)\n",
      "    \n",
      "    return node\n",
      "         \n",
      "#process node differently from way\n",
      "def shape_element(element):\n",
      "    node = {}  \n",
      "    if element.tag == \"node\":\n",
      "        return p_node(element)\n",
      "    if element.tag == \"way\":\n",
      "        return p_way(element)            \n",
      "    else:\n",
      "        return None\n",
      "\n",
      "\n",
      "def process_map(file_in, pretty = False):\n",
      "    file_out = \"{0}.json\".format(file_in)\n",
      "    data = []\n",
      "    with codecs.open(file_out, \"w\") as fo:\n",
      "        for _, element in ET.iterparse(file_in):\n",
      "            el = shape_element(element)\n",
      "          \n",
      "            if el:\n",
      "                data.append(el)\n",
      "                if pretty:\n",
      "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
      "                else:\n",
      "                    fo.write(json.dumps(el) + \"\\n\")\n",
      "    return data\n",
      "\n",
      "def test():\n",
      "    # NOTE: \n",
      "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
      "    # additional spaces to the output, making it significantly larger.\n",
      "    data = process_map('map.osm', pretty=False)\n",
      " \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load audit.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Wed Dec 17 10:32:50 2014\n",
      "\n",
      "@author: raphaeltam\n",
      "Audit the value of \"addr:stree\" key.  Extracts address typs such as street\n",
      "road, avenue etc. to identify variations that can be corrected with a \n",
      "map produced manually.\n",
      "'expected' is the list of accepted street_types and \"mapping\" maps variations\n",
      "to their expected forms.\n",
      "Minimal processing is done to correct a small number of steet_type variations, but\n",
      "much more needs to be done.\n",
      "Street types are written to a file \"st_types\" for further examination.  A correction strategy\n",
      "can be developed to improve data consistency and uniformity.\n",
      "\"\"\"\n",
      "import xml.etree.cElementTree as ET\n",
      "from collections import defaultdict\n",
      "import re\n",
      "import pprint\n",
      "\n",
      "OSMFILE = \"map.osm\"\n",
      "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
      "\n",
      "\n",
      "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
      "            \"Trail\", \"Parkway\", \"Commons\"]\n",
      "\n",
      "# mapping the variations to be fixed with update_name\n",
      "mapping = { \"St\": \"Street\",\n",
      "            \"St.\": \"Street\",\n",
      "            \"ST\": \"Street\",\n",
      "            \"Ave\": \"Avenue\",\n",
      "            \"Ave.\":\"Avenue\",\n",
      "            \"AVE\" :\"Avenue\",\n",
      "            \"Rd\":\"Road\",\n",
      "            \"Rd.\": \"Road\",\n",
      "            \"RD.\": \"Road\"\n",
      "            }\n",
      "\n",
      "\n",
      "def audit_street_type(street_types, street_name):\n",
      "    m = street_type_re.search(street_name)\n",
      "    if m:\n",
      "        street_type = m.group()\n",
      "        if street_type not in expected:\n",
      "            street_types[street_type].add(street_name)\n",
      "\n",
      "\n",
      "def is_street_name(elem):\n",
      "    return (elem.attrib['k'] == \"addr:street\")\n",
      "\n",
      "\n",
      "def audit(osmfile):\n",
      "    osm_file = open(osmfile, \"r\")\n",
      "    street_types = defaultdict(set)\n",
      "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
      "\n",
      "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
      "            for tag in elem.iter(\"tag\"):\n",
      "                if is_street_name(tag):\n",
      "                    audit_street_type(street_types, tag.attrib['v'])\n",
      "\n",
      "    return street_types\n",
      "\n",
      "\n",
      "def update_name(name, mapping):\n",
      "    m = street_type_re.search(name)\n",
      "    bad_name = m.group()\n",
      "    if bad_name in mapping.keys():\n",
      "        name = name.replace(bad_name, mapping[bad_name])\n",
      "        \n",
      "    return name\n",
      "\n",
      "\"\"\"\n",
      "Audit stret_types for variations in the vaue of \"addr:street\".\n",
      "Minimal corretions done with update_name \n",
      "Write street_type variations to a file for further examination. The objective\n",
      "is to develop a strategy on what to clean and how.\n",
      "\"\"\"\n",
      "def test():\n",
      "    st_types = audit(OSMFILE)\n",
      "    pprint.pprint(dict(st_types))\n",
      "    for st_type, ways in st_types.iteritems():\n",
      "        for name in ways:\n",
      "            better_name = update_name(name, mapping)\n",
      "    with open('st_types', 'w') as fo:\n",
      "        for st in st_types.keys():\n",
      "            fo.write (st+'\\n')\n",
      "    \n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'10675': set(['10675']),\n",
        " '2': set(['2']),\n",
        " '41st': set(['41st']),\n",
        " 'Alameda': set(['The Alameda']),\n",
        " 'Alley': set([\"Kahn's Alley\"]),\n",
        " 'Ave': set(['Greenwood Ave', 'San Pablo Ave', 'Shattuck Ave']),\n",
        " 'Ave.': set(['Fairmount Ave.']),\n",
        " 'Blvd': set(['Leimert Blvd', 'Monterey Blvd']),\n",
        " 'Broadway': set(['Broadway']),\n",
        " 'Circle': set(['Columbia Circle',\n",
        "                'Croydon Circle',\n",
        "                'Harding Circle',\n",
        "                'Saint James Circle',\n",
        "                'The Circle',\n",
        "                'Tyson Circle',\n",
        "                'Wilson Circle']),\n",
        " 'Crescent': set(['Clarendon Crescent']),\n",
        " 'Cut': set(['Short Cut']),\n",
        " 'Gardens': set(['Wildwood Gardens']),\n",
        " 'Hall': set(['McCone Hall']),\n",
        " 'Highway': set(['Eastshore Highway']),\n",
        " 'Leimert': set(['Leimert']),\n",
        " 'Loma': set(['La Loma']),\n",
        " 'Path': set(['Arden Path',\n",
        "              'Indian Rock Path',\n",
        "              'Mendocino Path',\n",
        "              'Oak Street Path',\n",
        "              'Parnassus Path']),\n",
        " 'Pl': set(['San Francisco/Oakland Bridge Toll Pl']),\n",
        " 'Plaza': set(['Bay Bridge Toll Plaza',\n",
        "               'Frank H Ogawa Plaza',\n",
        "               'Frank H. Ogawa Plaza']),\n",
        " 'St': set(['16th St',\n",
        "            '2nd St',\n",
        "            'Peralta St',\n",
        "            'Under I-580 Btwn Fruitvale / Champion St',\n",
        "            'Under I-880 @ 7th St & Linden St']),\n",
        " 'Steps': set(['Bancroft Steps']),\n",
        " 'Telegraph': set(['3605 Telegraph']),\n",
        " 'Terrace': set(['Alpine Terrace',\n",
        "                 'Broadway Terrace',\n",
        "                 'Greenwood Terrace',\n",
        "                 'Hawthorne Terrace',\n",
        "                 'Inverleith Terrace',\n",
        "                 'Park View Terrace',\n",
        "                 'Terrace',\n",
        "                 'Vernon Terrace']),\n",
        " 'View': set(['Norwood View']),\n",
        " 'Walk': set(['Fountain Walk', 'Rose Walk', 'Terrace Walk']),\n",
        " 'Way': set(['Abbott Way',\n",
        "             'Allston Way',\n",
        "             'Alston Way',\n",
        "             'Bancroft Way',\n",
        "             'Berkeley Way',\n",
        "             'Boulevard Way',\n",
        "             'Bret Harte Way',\n",
        "             'Buena Vista Way',\n",
        "             'Cambridge Way',\n",
        "             'Channing Way',\n",
        "             'Crystal Way',\n",
        "             'Dwight Way',\n",
        "             'Harold Way',\n",
        "             'Highland Way',\n",
        "             'Juanita Way',\n",
        "             'Martin Luther King Jr Way',\n",
        "             'Muir Way',\n",
        "             'Panoramic Way',\n",
        "             'Park Way',\n",
        "             'Poplar Way',\n",
        "             'Ranleigh Way',\n",
        "             'Richardson Way',\n",
        "             'Spring Way',\n",
        "             'Stoddard Way',\n",
        "             'Sylvan Way',\n",
        "             'Thomas L. Berkley Way',\n",
        "             'Wistaria Way',\n",
        "             'Woodland Way']),\n",
        " 'ave': set(['central ave'])}\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Some types such as Alameda, Way, Alley, Terrace, Plaza are legitimate names that should augment the \u2018expected\u2019 list.  \n",
      "However, other types such as Telegraph, 10675 and 41st seem to be entry errors that need to be fixed.  Still others such as \n",
      "Loma, Hall and Leimert need cross validation with other data sources.  So auditing the data turns up a long list of street \n",
      "types given by the addr:street key that need to be fixed."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\u201caudit.py\u2019 check for uniformity of the values in the \u2018addr:street\u2019 key, but how about the variations in the address keys \n",
      "themselves?  I used \u2018chk_addr.py\u2019 to understand those variations.  Address key variations will pose additional \n",
      "challenges to increase data uniformity. 'chk_addr.py' uses regex to find all variations with the string \u2018addr\u2019 as part of the \n",
      "key.     "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load chk_addr.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Tue Dec 16 18:22:37 2014\n",
      "\n",
      "@author: raphaeltam\n",
      "\"\"\"\n",
      "\n",
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "\"\"\"\n",
      "Get a feel of the address consistency problem in 2 passes.  This is the first pass to \n",
      "find tag with keys that have \"addr\" in all variations.  Use regex to match the addr \n",
      "string with any number of before and after characters.\n",
      "\"\"\"\n",
      "pattern = re.compile('.*addr*\\:*\\w*')\n",
      "\n",
      "\n",
      "def find_addr_var(filename):\n",
      "    addrs = set()\n",
      "    for _, element in ET.iterparse(filename):    \n",
      "        if element.tag == 'tag':\n",
      "            for de in element.iter('tag'):\n",
      "                if re.match(pattern, de.attrib['k']):\n",
      "                    addrs.add(de.attrib['k'])\n",
      "    return addrs\n",
      "\n",
      "\n",
      "def test():\n",
      "    variations  = find_addr_var('map.osm')\n",
      "    print variations\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['addr:housenumber', 'addr:unit', 'addr:full', 'addr:city', 'addr:housenumber:source', 'addr:province', 'addr:postcode', 'addr:interpolation', 'addr:housename', 'addr:state', 'address', 'addr:county', 'addr:country', 'addr:suite', 'addr:street'])\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "By manually examining the set from \u2018chk_addr.py\u2019, I get a list of variations that challenge the data model used in \n",
      "data.py .  \u2018addr_problems.py\u2019 scans the dataset for keys with these variations and save the address information of these \n",
      "problematic elements in a csv file.  The address information of these objects is saved to \u2018problem_addr.csv\u2019. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load addr_problems.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Sat Dec 20 00:51:43 2014\n",
      "\n",
      "@author: raphaeltam\n",
      "\"\"\"\n",
      "import pprint\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "\"\"\"\n",
      "Inspect and manully remove expected keys from the set obtained from chk_addr.py\n",
      "to get a 'mapping' list.  Expected keys such as 'addr:housenumber' and 'addr:\n",
      "street' do not go into the mapping list.  The list produced is\n",
      "the set of keys that should potentially be corrected.\n",
      "\n",
      "With all the vairations in the mapping list, run through elements to find abnormal\n",
      "keys and use writedict to save the key-value pairs to a csv file for visual\n",
      "examination.\n",
      "\n",
      "\"\"\"\n",
      "def addr_excep(filename):\n",
      "    data = []\n",
      "    mapping =['addr:unit', 'addr:full',\n",
      "    'addr:housenumber:source', 'addr:province', \n",
      "    'addr:interpolation', 'addr:housename', \n",
      "    'address', 'addr:suite']\n",
      "\n",
      "    for _, element in ET.iterparse(filename):    \n",
      "        if element.tag == 'tag':\n",
      "            for t in element.iter('tag'):\n",
      "                for odd in mapping:\n",
      "                    if t.attrib['k'] == odd:\n",
      "                        data.append(element) \n",
      "    return data\n",
      "\n",
      "def print_to_file(v):\n",
      "    fieldnames = ['addr:housenumber', 'addr:unit', 'addr:full', 'addr:city', \\\n",
      "    'addr:housenumber:source', 'addr:province', 'addr:postcode', \n",
      "    'addr:interpolation', 'addr:housename', 'addr:state', \n",
      "    'address', 'addr:county', 'addr:country', 'addr:suite', 'addr:street']\n",
      "\n",
      "    import csv\n",
      "    with open('problem_addr.csv', 'w') as fo:\n",
      "        wr = csv.DictWriter (fo, fieldnames=fieldnames, restval='',\\\n",
      "        extrasaction='ignore')\n",
      "        wr.writeheader()\n",
      "        for el in v:\n",
      "            dic = {}\n",
      "            for t in el.iter('tag'):\n",
      "                dic[t.attrib['k']] = t.attrib['v']\n",
      "            wr.writerow(dic)    \n",
      "\n",
      "def test():\n",
      "    v  = addr_excep('map.osm')\n",
      "    print_to_file(v)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\u2018problem_addr.csv\u2019  shows that  keys such as \u201caddr:unit\u201d and \u201caddr:suite\u201d should be added to the data model.  \n",
      "They seem to be legitimate information that pinpoints addresses beyond \u201chousenumber\u2019.  \u201caddress\u201d , \u201caddr:full\u201d and \n",
      "\u201caddr:province\u201d seem to be correctable variations of the data model.   Additional code can make them consistent.\n",
      "However, \u201caddr:housename\u201d could be the name of the building or it could be equivalent to \u201caddr:housenumber\u201d.  \n",
      "\u201caddr:interpolation\u201d and \u201caddr:housenumber:source\u201d are open to interpretation.  These keys are associated with addressees \n",
      "but they cannot be corrected without a second cross validation source.  These corrections will be highly dependent on \n",
      "dataset or locale.  Code that improves consistency on this dataset may not be effective on another."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "I was particularly interested in the completeness of any node that has \u201crestaurant\u201d as its \u201camenity\u201d.   After importing the \n",
      "data to the \u2018example\u2019 mongo database, I wrote \u2018pr_cuisine.py\u2019 to find if there are any restaurants that are not assigned a \n",
      "cuisine.  The result was written to a file \u201ccuisine_types\u201d.   Out of 470 restaurants, 144 of them have no cuisine information \n",
      "available."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load pr_cuisine.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Thu Dec 18 08:23:51 2014\n",
      "\n",
      "@author: raphaeltam\n",
      "Use mongo queries to count the number of different cuisines offered by restaurants \n",
      "in the area.  Save cuisine types and number of restaurants that offers a particular\n",
      "cuisine to a file named \"updated_cuisine_types\". \n",
      "\n",
      "\"\"\"\n",
      "import pprint\n",
      "def get_db(db_name):\n",
      "    from pymongo import MongoClient\n",
      "    client = MongoClient('localhost:27017')\n",
      "    db = client[db_name]\n",
      "    return db\n",
      "\n",
      "def make_pipeline():\n",
      "    pipeline = [{'$match':{'amenity':'restaurant'}},\n",
      "              {'$group':{'_id':'$cuisine','count':{'$sum':1}}}\n",
      "                ]    \n",
      "    return pipeline\n",
      "\n",
      "  \n",
      "def get_cui(db, pipeline):\n",
      "    result = db.map.osm.aggregate(pipeline)\n",
      "    return result\n",
      "    \n",
      "def print_to_file (result):\n",
      "    with open('example_cuisine_types','w') as fo:\n",
      "        for r in result['result']:\n",
      "            fo.write('count: '+str(r['count'])+'\\t'+'cuisine: '+str(r['_id'])+'\\n')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    db = get_db('example')\n",
      "    pipeline = make_pipeline()\n",
      "    result = get_cui(db, pipeline)\n",
      "    print 'Number of distinct cuisines incl. None = {0}'.format(len(result['result']))\n",
      "    print_to_file(result)\n",
      "    \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Furthermore, some values are in upper case while the majority of them are not.  Changing from upper to all lower case is a \n",
      "quick way to improve consistency because \u2018Italian\u2019 and \u2018italian\u2019 should be the same cuisine.   I did that with \n",
      "\u2018update_cuisine.py\u2019.  Running \u2018pr_cuisine.py\u2019 again shows that the number of cuisine types is reduced from 62 to 55.  \n",
      "The result is captured in the file \u2018updated_cuisine_types\u2019. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load update_cuisine.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Thu Dec 18 19:59:03 2014\n",
      "\n",
      "@author: raphaeltam\n",
      "Minimal cleaning of cuisine types: convert all to lower case and correct obvious \n",
      "inconsistencies due to spelling errors.\n",
      "\"\"\"\n",
      "import re\n",
      "mapping = ['Mexican','Pizza','Thai','Pakistani','Brasilian','Chinese']\n",
      "def get_db(db_name):\n",
      "    from pymongo import MongoClient\n",
      "    client = MongoClient('localhost:27017')\n",
      "    db = client[db_name]\n",
      "    return db\n",
      "\n",
      "def make_pipeline():\n",
      "    pipeline = [{'$match':{'amenity':'restaurant'}},\n",
      "              {'$group':{'_id':'$cuisine','count':{'$sum':1}}}\n",
      "                ]\n",
      "    return pipeline   \n",
      "\n",
      "def cor_cap(cap, db):\n",
      "    db.map.osm.update({'cuisine':cap},\n",
      "                      {\"$set\": {'cuisine':cap.lower()}},multi=True\n",
      "                      )\n",
      "    return\n",
      "    \n",
      "def cor_oddballs(db):\n",
      "    db.map.osm.update({'cuisine':'Comfort_Food'},\n",
      "                      {'$set': {'cuisine':'comfort_food'}}\n",
      "                      )\n",
      "    db.map.osm.update({'cuisine':'thai:lao'},\n",
      "                      {'$set': {'cuisine':'thai;lao'}}\n",
      "                      )\n",
      "    db.map.osm.update({'cuisine':'california'},\n",
      "                      {'$set': {'cuisine':'californian'}}\n",
      "                      )\n",
      "    return\n",
      "        \n",
      "if __name__ == '__main__':\n",
      "    db = get_db('example')\n",
      "    for cuisine in mapping:\n",
      "        cor_cap(cuisine,db)\n",
      "    cor_oddballs(db)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "I believe missing cuisine information is simply \u201cthe tip of the iceberg\u201d with respect to completeness and accuracy.   I suspect\n",
      "that a lot of cleaning has to be done.  I am not aware of a gold standard.  But another data source should prove valuable in \n",
      "cleaning the map."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Data Overview:\n",
      "    Data Size: 50.8 MB\n",
      "    No of ways: 28,037 (node_count.py)\n",
      "    No of nodes: 211,725 (node_count.py)\n",
      "    No of users: 444 (users.py)\n",
      "    No. of restaurants: 470 (count_res.py)\n",
      "    No. of cuisines: 55 (pr_cuisine.py)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Data from Yelp.com can be used as a second source to check the data for accuracy and completeness.  Yelp is a curated crowd \n",
      "source site that provides users with ratings and reviews of businesses in the local area.  Since it is curated, consistency, \n",
      "uniformity and validity issues are kept to a minimum.   As such, address, phone number and amenity information of businesses \n",
      "can be updated with the data from Yelp to improve accuracy and completeness.  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "I obtained authentication information from the Yelp developer site.  Modifying slightly the sample code from the site, I was \n",
      "able to programmatically obtain address and amenity related data for businesses in \u2018command_line.py\u2019.  Given a term such as the\n",
      "name of a business, and a location that can be a city, postal code or neighborhood, the API returns information in JSON format.\n",
      "As an example, data returned for a query on the restaurant \u2018Cugini\u2019 is captured in \u2018yelp_query\u2019."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load command_line.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Yelp API v2.0 code sample.\n",
      "\n",
      "This program demonstrates the capability of the Yelp API version 2.0\n",
      "by using the Search API to query for businesses by a search term and location,\n",
      "and the Business API to query additional information about the top result\n",
      "from the search query.\n",
      "\n",
      "Please refer to http://www.yelp.com/developers/documentation for the API documentation.\n",
      "\n",
      "This program requires the Python oauth2 library, which you can install via:\n",
      "`pip install -r requirements.txt`.\n",
      "\n",
      "Sample usage of the program:\n",
      "`python sample.py --term=\"bars\" --location=\"San Francisco, CA\"`\n",
      "\"\"\"\n",
      "import argparse\n",
      "import json\n",
      "import pprint\n",
      "import sys\n",
      "import urllib\n",
      "import urllib2\n",
      "import codecs\n",
      "\n",
      "import oauth2\n",
      "\n",
      "\n",
      "API_HOST = 'api.yelp.com'\n",
      "DEFAULT_TERM = 'dinner'\n",
      "DEFAULT_LOCATION = 'San Francisco, CA'\n",
      "SEARCH_LIMIT = 3\n",
      "SEARCH_PATH = '/v2/search/'\n",
      "BUSINESS_PATH = '/v2/business/'\n",
      "\n",
      "# OAuth credential placeholders that must be filled in by users.\n",
      "CONSUMER_KEY = \"rcv6FbXLQWzWsX_aqRki6w\"\n",
      "CONSUMER_SECRET = \"-IsAQCbH6F30Ru1xpDQyEBhyIT8\"\n",
      "TOKEN = \"BGHFQ9QVD6oxejcRhEqc2sBypjnczUMU\"\n",
      "TOKEN_SECRET = \"_yot0Cj7BCEop0p-3C_BK6SNnZU\"\n",
      "\n",
      "\n",
      "def request(host, path, url_params=None):\n",
      "    \"\"\"Prepares OAuth authentication and sends the request to the API.\n",
      "\n",
      "    Args:\n",
      "        host (str): The domain host of the API.\n",
      "        path (str): The path of the API after the domain.\n",
      "        url_params (dict): An optional set of query parameters in the request.\n",
      "\n",
      "    Returns:\n",
      "        dict: The JSON response from the request.\n",
      "\n",
      "    Raises:\n",
      "        urllib2.HTTPError: An error occurs from the HTTP request.\n",
      "    \"\"\"\n",
      "    url_params = url_params or {}\n",
      "    url = 'http://{0}{1}?'.format(host, path)\n",
      "\n",
      "    consumer = oauth2.Consumer(CONSUMER_KEY, CONSUMER_SECRET)\n",
      "    oauth_request = oauth2.Request(method=\"GET\", url=url, parameters=url_params)\n",
      "\n",
      "    oauth_request.update(\n",
      "        {\n",
      "            'oauth_nonce': oauth2.generate_nonce(),\n",
      "            'oauth_timestamp': oauth2.generate_timestamp(),\n",
      "            'oauth_token': TOKEN,\n",
      "            'oauth_consumer_key': CONSUMER_KEY\n",
      "        }\n",
      "    )\n",
      "    token = oauth2.Token(TOKEN, TOKEN_SECRET)\n",
      "    oauth_request.sign_request(oauth2.SignatureMethod_HMAC_SHA1(), consumer, token)\n",
      "    signed_url = oauth_request.to_url()\n",
      "    print signed_url\n",
      "    print 'Querying {0} ...'.format(url)\n",
      "\n",
      "    conn = urllib2.urlopen(signed_url, None)\n",
      "    try:\n",
      "        response = json.loads(conn.read())\n",
      "    finally:\n",
      "        conn.close()\n",
      "\n",
      "    return response\n",
      "\n",
      "def search(term, location):\n",
      "    \"\"\"Query the Search API by a search term and location.\n",
      "\n",
      "    Args:\n",
      "        term (str): The search term passed to the API.\n",
      "        location (str): The search location passed to the API.\n",
      "\n",
      "    Returns:\n",
      "        dict: The JSON response from the request.\n",
      "    \"\"\"\n",
      "    \n",
      "    url_params = {\n",
      "        'term': term.replace(' ', '+'),\n",
      "        'location': location.replace(' ', '+'),\n",
      "#        'category_filter': 'restaurant'\n",
      "        \n",
      "        \n",
      "    }\n",
      "    return request(API_HOST, SEARCH_PATH, url_params=url_params)\n",
      "\n",
      "def get_business(business_id):\n",
      "    \"\"\"Query the Business API by a business ID.\n",
      "\n",
      "    Args:\n",
      "        business_id (str): The ID of the business to query.\n",
      "\n",
      "    Returns:\n",
      "        dict: The JSON response from the request.\n",
      "    \"\"\"\n",
      "    business_path = BUSINESS_PATH + business_id\n",
      "\n",
      "    return request(API_HOST, business_path)\n",
      "\n",
      "def query_api(term, location):\n",
      "    \"\"\"Queries the API by the input values from the user.\n",
      "\n",
      "    Args:\n",
      "        term (str): The search term to query.\n",
      "        location (str): The location of the business to query.\n",
      "    \"\"\"\n",
      "    response = search(term, location)\n",
      "\n",
      "    businesses = response.get('businesses')\n",
      "\n",
      "    if not businesses:\n",
      "        print 'No businesses for {0} in {1} found.'.format(term, location)\n",
      "        return\n",
      "\n",
      "    business_id = businesses[0]['id']\n",
      "\n",
      "    print '{0} businesses found, querying business info for the top result \"{1}\" ...'.format(\n",
      "        len(businesses),\n",
      "        business_id\n",
      "    )\n",
      "\n",
      "    response = get_business(business_id)\n",
      "\n",
      "    print 'Result for business \"{0}\" found:'.format(business_id)\n",
      "    pprint.pprint(response, indent=2)\n",
      "    print_to_file(response)\n",
      "\n",
      "def print_to_file(response):\n",
      "    with codecs.open('yelp_query', 'wb')as fo:\n",
      "        fo.write(json.dumps(response, indent=2))\n",
      "\n",
      "def main():\n",
      "\n",
      "    term = 'Cuigini'\n",
      "    location = 'Berkely, CA'\n",
      "    pos = [\"37.873196\", \"-122.268714\"]\n",
      "    cat = 'restaurant'\n",
      "\n",
      "    try:\n",
      "        query_api(term, location)\n",
      "    except urllib2.HTTPError as error:\n",
      "        sys.exit('Encountered HTTP error {0}. Abort program.'.format(error.code))\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://api.yelp.com/v2/search/?term=Cuigini&oauth_token=BGHFQ9QVD6oxejcRhEqc2sBypjnczUMU&location=Berkely%2C%2BCA&oauth_nonce=40717665&oauth_timestamp=1419806606&oauth_signature=%2BxvnTkZl%2BMtP6ZYicsFbq83vh94%3D&oauth_consumer_key=rcv6FbXLQWzWsX_aqRki6w&oauth_signature_method=HMAC-SHA1\n",
        "Querying http://api.yelp.com/v2/search/? ...\n",
        "2 businesses found, querying business info for the top result \"cugini-restaurant-albany-2\" ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://api.yelp.com/v2/business/cugini-restaurant-albany-2?oauth_nonce=56095105&oauth_timestamp=1419806606&oauth_consumer_key=rcv6FbXLQWzWsX_aqRki6w&oauth_signature_method=HMAC-SHA1&oauth_token=BGHFQ9QVD6oxejcRhEqc2sBypjnczUMU&oauth_signature=TiRND%2FIgCzWGYKSURRg2AaImKjY%3D\n",
        "Querying http://api.yelp.com/v2/business/cugini-restaurant-albany-2? ...\n",
        "Result for business \"cugini-restaurant-albany-2\" found:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{ u'categories': [[u'Italian', u'italian']],\n",
        "  u'display_phone': u'+1-510-558-9000',\n",
        "  u'id': u'cugini-restaurant-albany-2',\n",
        "  u'image_url': u'http://s3-media2.fl.yelpcdn.com/bphoto/fXbNFmrQolz5rIjUEKJiwg/ms.jpg',\n",
        "  u'is_claimed': False,\n",
        "  u'is_closed': False,\n",
        "  u'location': { u'address': [u'1556 Solano Ave'],\n",
        "                 u'city': u'Albany',\n",
        "                 u'coordinate': { u'latitude': 37.8909927606583,\n",
        "                                  u'longitude': -122.28530600667},\n",
        "                 u'country_code': u'US',\n",
        "                 u'cross_streets': u'Ordway St & Peralta Ave',\n",
        "                 u'display_address': [ u'1556 Solano Ave',\n",
        "                                       u'Berkeley Hills',\n",
        "                                       u'Albany, CA 94707'],\n",
        "                 u'geo_accuracy': 8.0,\n",
        "                 u'neighborhoods': [u'Berkeley Hills'],\n",
        "                 u'postal_code': u'94707',\n",
        "                 u'state_code': u'CA'},\n",
        "  u'menu_date_updated': 1387603490,\n",
        "  u'menu_provider': u'single_platform',\n",
        "  u'mobile_url': u'http://m.yelp.com/biz/cugini-restaurant-albany-2',\n",
        "  u'name': u'Cugini Restaurant',\n",
        "  u'phone': u'5105589000',\n",
        "  u'rating': 3.5,\n",
        "  u'rating_img_url': u'http://s3-media1.fl.yelpcdn.com/assets/2/www/img/5ef3eb3cb162/ico/stars/v1/stars_3_half.png',\n",
        "  u'rating_img_url_large': u'http://s3-media3.fl.yelpcdn.com/assets/2/www/img/bd9b7a815d1b/ico/stars/v1/stars_large_3_half.png',\n",
        "  u'rating_img_url_small': u'http://s3-media1.fl.yelpcdn.com/assets/2/www/img/2e909d5d3536/ico/stars/v1/stars_small_3_half.png',\n",
        "  u'review_count': 173,\n",
        "  u'reviews': [ { u'excerpt': u'So... I gave them a second chance. I wanted to try their dessert so bad! Plus, my husband loves Italian food! \\n\\nMy second time around was such a contrast to...',\n",
        "                  u'id': u'G_yGtZf2Lb2xhT43fTB5vQ',\n",
        "                  u'rating': 5,\n",
        "                  u'rating_image_large_url': u'http://s3-media3.fl.yelpcdn.com/assets/2/www/img/22affc4e6c38/ico/stars/v1/stars_large_5.png',\n",
        "                  u'rating_image_small_url': u'http://s3-media1.fl.yelpcdn.com/assets/2/www/img/c7623205d5cd/ico/stars/v1/stars_small_5.png',\n",
        "                  u'rating_image_url': u'http://s3-media1.fl.yelpcdn.com/assets/2/www/img/f1def11e4e79/ico/stars/v1/stars_5.png',\n",
        "                  u'time_created': 1415223873,\n",
        "                  u'user': { u'id': u'Mc_OgcSGQ-S1JHF7JSlBHQ',\n",
        "                             u'image_url': u'http://s3-media1.fl.yelpcdn.com/photo/tTbY-YmydAlkEATEOr9G8A/ms.jpg',\n",
        "                             u'name': u'Alyssa P.'}}],\n",
        "  u'snippet_image_url': u'http://s3-media1.fl.yelpcdn.com/photo/tTbY-YmydAlkEATEOr9G8A/ms.jpg',\n",
        "  u'snippet_text': u'So... I gave them a second chance. I wanted to try their dessert so bad! Plus, my husband loves Italian food! \\n\\nMy second time around was such a contrast to...',\n",
        "  u'url': u'http://www.yelp.com/biz/cugini-restaurant-albany-2'}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "By programmatically building a list of businesses, one can extract corresponding information from Yelp to improve on the OSM \n",
      "map database.   If information from the sources does not match, I would prefer to take the information from Yelp. Because the \n",
      "site is used widely, inaccuracies and inconsistences tend to be corrected.  Since it is curated, uniformity should not be an \n",
      "issue.   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "However, even with this implementation, data cleaning of the OSM dataset still poses a challenge for non-business related data \n",
      "such as homes, factories and office buildings.  Yelp provides information on local businesses only, while the OSM data includes\n",
      "nodes that encompass a much wider variety.   Still other sources are needed to validate the data on \u2018ways\u2019.   I have not \n",
      "identified suitable sources thus far.  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}